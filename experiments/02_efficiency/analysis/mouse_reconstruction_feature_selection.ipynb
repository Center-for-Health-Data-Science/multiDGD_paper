{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import math\n",
    "\n",
    "#os.chdir('/Users/dbm829/Documents/work/Projects/GitHub/omicsDGD/')\n",
    "save_dir = '../../results/trained_models/'\n",
    "data_name = 'mouse_gastrulation'\n",
    "random_seed = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_error_per_sample(target, output, reduction_type='ms'):\n",
    "    '''compute sample-wise error\n",
    "    It can be of type `ms` (mean squared) or `ma` (mean absolute)\n",
    "    '''\n",
    "    error = target - output\n",
    "    if reduction_type == 'ms':\n",
    "        return torch.mean(error**2, dim=-1)\n",
    "    elif reduction_type == 'ma':\n",
    "        return torch.mean(torch.abs(error), dim=-1)\n",
    "    else:\n",
    "        raise ValueError('invalid reduction type given. Can only be `ms` or `ma`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_output_scores(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tp = tp.sum()\n",
    "    fp = fp.sum()\n",
    "    tn = tn.sum()\n",
    "    fn = fn.sum()\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    positive_likelihood_ratio = tpr/fpr\n",
    "    negative_likelihood_ratio = fnr/tnr\n",
    "\n",
    "    return tpr.item(), tnr.item(), balanced_accuracy.item(), positive_likelihood_ratio.item(), negative_likelihood_ratio.item()\n",
    "\n",
    "def balanced_accuracy_with_sem(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    #ba_mean = balanced_accuracy.clone().mean().item()\n",
    "    _, _, ba_mean, _, _ = binary_output_scores(target, output, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    ba_error = balanced_accuracy.std() / math.sqrt(balanced_accuracy.shape[0])\n",
    "\n",
    "    return ba_mean, ba_error.item()\n",
    "\n",
    "def classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''calculating true positives, false positives, true negatives and false negatives'''\n",
    "    #print('classifying binary output')\n",
    "    \n",
    "    n_samples = target.shape[0]\n",
    "    true_positives = torch.zeros((n_samples))\n",
    "    false_positives = torch.zeros((n_samples))\n",
    "    true_negatives = torch.zeros((n_samples))\n",
    "    false_negatives = torch.zeros((n_samples))\n",
    "    \n",
    "    for i in range(int(n_samples/batch_size)+1):\n",
    "        #print(round(i/(int(n_samples/batch_size))*100),'%')\n",
    "        start = i*batch_size\n",
    "        end = min((i+1)*batch_size,n_samples)\n",
    "        indices = np.arange(start,end,1)\n",
    "        x_accessibility = binarize(torch.Tensor(target[indices,:])).int()\n",
    "        y_accessibility = output[indices,:]\n",
    "        if type(y_accessibility) is not torch.Tensor:\n",
    "            if type(y_accessibility) == pd.core.frame.DataFrame:\n",
    "                y_accessibility = torch.from_numpy(y_accessibility.values)\n",
    "                y_accessibility = y_accessibility.detach().cpu()\n",
    "        else:\n",
    "            y_accessibility = y_accessibility.detach().cpu()*scaling_factor[indices]\n",
    "        y_accessibility = binarize(y_accessibility, threshold).int()\n",
    "        if feature_indices is not None:\n",
    "            x_accessibility = x_accessibility[:,feature_indices]\n",
    "            y_accessibility = y_accessibility[:,feature_indices]\n",
    "        p = (x_accessibility == 1)\n",
    "        pp = (y_accessibility == 1)\n",
    "        true_positives[indices] = torch.logical_and(p,pp).sum(-1).float()\n",
    "        true_negatives[indices] = torch.logical_and(~p,~pp).sum(-1).float()\n",
    "        false_positives[indices] = (y_accessibility > x_accessibility).sum(-1).float()\n",
    "        false_negatives[indices] = (y_accessibility < x_accessibility).sum(-1).float()\n",
    "    \n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "def binarize(x, threshold=0.5):\n",
    "    x[x >= threshold] = 1\n",
    "    x[x < threshold] = 0\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recalculate losses for sample-wise with SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test and reconstructions from the saved files\n",
    "test_gex = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_test_counts_gex.npy')\n",
    "recon_gex = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_test_recon_gex.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.714585781097412  +/-  0.012759659439325333\n"
     ]
    }
   ],
   "source": [
    "n_samples = test_gex.shape[0]\n",
    "errors = compute_error_per_sample(torch.tensor(test_gex), torch.tensor(recon_gex)*torch.tensor(test_gex).sum(axis=1).unsqueeze(1), reduction_type='ms')\n",
    "out_errors = torch.sqrt(errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test and reconstructions from the saved files\n",
    "test_atac = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_test_counts_atac.npy')\n",
    "recon_atac = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_test_recon_atac.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy:  0.7324193716049194  +/-  0.0006929467199370265\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.2\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now make a file for the feature selection indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n"
     ]
    }
   ],
   "source": [
    "# get the data and the indices of the overlapping features\n",
    "# first the full set\n",
    "\"\"\"\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import mudata as md\n",
    "gex = ad.read_h5ad('../../data/mouse_gastrulation/raw/anndata.h5ad')\n",
    "atac = ad.read_h5ad('../../data/mouse_gastrulation/raw/PeakMatrix_anndata.h5ad')\n",
    "ids_shared = list(set(gex.obs['sample'].index.values).intersection(set(atac.obs['sample'].index.values)))\n",
    "ids_gex = np.where(gex.obs['sample'].index.isin(ids_shared))[0]\n",
    "ids_atac = np.where(atac.obs['sample'].index.isin(ids_shared))[0]\n",
    "gex = gex[ids_gex]\n",
    "atac = atac[ids_atac]\n",
    "threshold = 0.00\n",
    "mudata = md.MuData({'rna': gex, 'atac': atac})\n",
    "mudata.obs['stage'] = mudata['atac'].obs['stage']\n",
    "mudata.obs['celltype'] = mudata['rna'].obs['celltype']\n",
    "train_indices = np.where(mudata.obs[\"train_val_test\"] == \"train\")[0]\n",
    "trainset = mudata[train_indices,:].copy()\n",
    "test_indices = np.where(mudata.obs[\"train_val_test\"] == \"test\")[0]\n",
    "testset = mudata[test_indices,:].copy()\n",
    "mudata, gex, atac = None, None, None\n",
    "modality_switch_full = testset['rna'].X.shape[1]\n",
    "\n",
    "# now the subset\n",
    "data_subset = md.read('../../data/mouse_gastrulation.h5mu', backed=False)\n",
    "rna_indices = [i for i, x in enumerate(testset.var.index) if x in data_subset['rna'].var.index]\n",
    "atac_indices = [i-modality_switch_full for i, x in enumerate(testset.var.index) if x in data_subset['atac'].var.index]\n",
    "\n",
    "# save indices as csv file\n",
    "indices_df = pd.concat(\n",
    "    (pd.DataFrame({'idx': rna_indices,\n",
    "                           'modality': 'rna'}),\n",
    "    pd.DataFrame({'idx': atac_indices,\n",
    "                           'modality': 'atac'})), axis=0\n",
    ")\n",
    "#indices_df.to_csv('data/mouse_gastrulation/five_percent_indices.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_df = pd.read_csv('../../../data/mouse_gastrulation_five_percent_indices.csv')\n",
    "rna_indices = indices_df[indices_df['modality'] == 'rna']['idx'].values\n",
    "atac_indices = indices_df[indices_df['modality'] == 'atac']['idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_gex = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_scale5_featselect0_test_recon_gex.npy')\n",
    "recon_gex = recon_gex[:, rna_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.6939202547073364  +/-  0.01272590272128582\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "n_samples = test_gex.shape[0]\n",
    "errors = compute_error_per_sample(torch.tensor(test_gex), torch.tensor(recon_gex)*torch.tensor(test_gex).sum(axis=1).unsqueeze(1), reduction_type='ms')\n",
    "out_errors = torch.sqrt(errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_atac = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_scale5_featselect0_test_recon_atac.npy')\n",
    "recon_atac = recon_atac[:, atac_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy:  0.739676833152771  +/-  0.0007066355901770294\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data # old version\n",
    "\n",
    "threshold = 0.2\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6792690753936768  +/-  0.0007066355901770294\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\"\"\"\n",
    "threshold = 0.2\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import mudata as md\n",
    "gex = ad.read_h5ad('../../../data/raw/mouse_gastrulation_anndata.h5ad')\n",
    "atac = ad.read_h5ad('../../../data/raw/mouse_gastrulation_PeakMatrix_anndata.h5ad')\n",
    "ids_shared = list(set(gex.obs['sample'].index.values).intersection(set(atac.obs['sample'].index.values)))\n",
    "ids_gex = np.where(gex.obs['sample'].index.isin(ids_shared))[0]\n",
    "ids_atac = np.where(atac.obs['sample'].index.isin(ids_shared))[0]\n",
    "gex = gex[ids_gex]\n",
    "atac = atac[ids_atac]\n",
    "threshold = 0.00\n",
    "mudata = md.MuData({'rna': gex, 'atac': atac})\n",
    "mudata_original = md.read('../../../data/mouse_gastrulation.h5mu', backed=False)\n",
    "mudata.obs = mudata_original.obs.copy()\n",
    "mudata_original = None\n",
    "train_indices = np.where(mudata.obs[\"train_val_test\"] == \"train\")[0]\n",
    "trainset = mudata[train_indices,:].copy()\n",
    "test_indices = np.where(mudata.obs[\"train_val_test\"] == \"test\")[0]\n",
    "testset = mudata[test_indices,:].copy()\n",
    "modality_switch_full = testset['rna'].X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = torch.cat(\n",
    "    (torch.tensor(np.asarray(testset['rna'].X.sum(-1))),\n",
    "    torch.tensor(np.asarray(testset['atac'].X.sum(-1)))),\n",
    "    dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <08E12B12-6183-307E-BDA0-374FA8EBA2C9> /Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/image.so\n",
      "  Expected in:     <57D24B07-8B24-3888-A2B5-2B4C95434BA4> /Users/dbm829/Library/Python/3.9/lib/python/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n"
     ]
    }
   ],
   "source": [
    "# first the model on all data\n",
    "\n",
    "import scipy\n",
    "import scvi\n",
    "train_stages = trainset.obs['stage'].values\n",
    "test_stages = testset.obs['stage'].values\n",
    "# now VAE\n",
    "trainset = ad.AnnData(scipy.sparse.hstack((trainset['rna'].X,trainset['atac'].X))) # making test set anndata\n",
    "trainset.var_names_make_unique()\n",
    "trainset.obs['stage'] = train_stages\n",
    "trainset.obs['modality'] = 'paired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>MuData object with n_obs × n_vars = 5686 × 224536\n",
       "  obs:\t&#x27;train_val_test&#x27;, &#x27;stage&#x27;, &#x27;celltype&#x27;, &#x27;observable&#x27;, &#x27;covariate_stage&#x27;\n",
       "  2 modalities\n",
       "    rna:\t5686 x 32285\n",
       "      obs:\t&#x27;barcode&#x27;, &#x27;sample&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;nCount_RNA&#x27;, &#x27;mitochondrial_percent_RNA&#x27;, &#x27;ribosomal_percent_RNA&#x27;, &#x27;stage&#x27;, &#x27;genotype&#x27;, &#x27;pass_rnaQC&#x27;, &#x27;doublet_score&#x27;, &#x27;doublet_call&#x27;, &#x27;celltype&#x27;, &#x27;celltype.score&#x27;, &#x27;closest.cell&#x27;\n",
       "      var:\t&#x27;gene&#x27;\n",
       "    atac:\t5686 x 192251\n",
       "      obs:\t&#x27;BlacklistRatio&#x27;, &#x27;nDiFrags&#x27;, &#x27;nFrags&#x27;, &#x27;nMonoFrags&#x27;, &#x27;nMultiFrags&#x27;, &#x27;NucleosomeRatio&#x27;, &#x27;PassQC&#x27;, &#x27;PromoterRatio&#x27;, &#x27;ReadsInBlacklist&#x27;, &#x27;ReadsInPromoter&#x27;, &#x27;ReadsInTSS&#x27;, &#x27;Sample&#x27;, &#x27;TSSEnrichment&#x27;, &#x27;barcode&#x27;, &#x27;sample&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;nCount_RNA&#x27;, &#x27;mitochondrial_percent_RNA&#x27;, &#x27;ribosomal_percent_RNA&#x27;, &#x27;stage&#x27;, &#x27;genotype&#x27;, &#x27;pass_rnaQC&#x27;, &#x27;doublet_score&#x27;, &#x27;doublet_call&#x27;, &#x27;celltype.mapped&#x27;, &#x27;celltype.score&#x27;, &#x27;closest.cell&#x27;, &#x27;TSSEnrichment_atac&#x27;, &#x27;ReadsInTSS_atac&#x27;, &#x27;PromoterRatio_atac&#x27;, &#x27;NucleosomeRatio_atac&#x27;, &#x27;nFrags_atac&#x27;, &#x27;BlacklistRatio_atac&#x27;, &#x27;ReadsInPeaks&#x27;, &#x27;FRIP&#x27;, &#x27;cell&#x27;\n",
       "      var:\t&#x27;idx&#x27;, &#x27;chr&#x27;, &#x27;start&#x27;, &#x27;end&#x27;\n",
       "      uns:\t&#x27;celltype_colors&#x27;, &#x27;stage_colors&#x27;</pre>"
      ],
      "text/plain": [
       "MuData object with n_obs × n_vars = 5686 × 224536\n",
       "  obs:\t'train_val_test', 'stage', 'celltype', 'observable', 'covariate_stage'\n",
       "  2 modalities\n",
       "    rna:\t5686 x 32285\n",
       "      obs:\t'barcode', 'sample', 'nFeature_RNA', 'nCount_RNA', 'mitochondrial_percent_RNA', 'ribosomal_percent_RNA', 'stage', 'genotype', 'pass_rnaQC', 'doublet_score', 'doublet_call', 'celltype', 'celltype.score', 'closest.cell'\n",
       "      var:\t'gene'\n",
       "    atac:\t5686 x 192251\n",
       "      obs:\t'BlacklistRatio', 'nDiFrags', 'nFrags', 'nMonoFrags', 'nMultiFrags', 'NucleosomeRatio', 'PassQC', 'PromoterRatio', 'ReadsInBlacklist', 'ReadsInPromoter', 'ReadsInTSS', 'Sample', 'TSSEnrichment', 'barcode', 'sample', 'nFeature_RNA', 'nCount_RNA', 'mitochondrial_percent_RNA', 'ribosomal_percent_RNA', 'stage', 'genotype', 'pass_rnaQC', 'doublet_score', 'doublet_call', 'celltype.mapped', 'celltype.score', 'closest.cell', 'TSSEnrichment_atac', 'ReadsInTSS_atac', 'PromoterRatio_atac', 'NucleosomeRatio_atac', 'nFrags_atac', 'BlacklistRatio_atac', 'ReadsInPeaks', 'FRIP', 'cell'\n",
       "      var:\t'idx', 'chr', 'start', 'end'\n",
       "      uns:\t'celltype_colors', 'stage_colors'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n"
     ]
    }
   ],
   "source": [
    "scvi.model.MULTIVI.setup_anndata(trainset, batch_key='stage')\n",
    "testset = ad.AnnData(scipy.sparse.hstack((testset['rna'].X,testset['atac'].X)))\n",
    "testset.var_names_make_unique()\n",
    "testset.obs['stage'] = test_stages\n",
    "testset.obs['modality'] = 'paired'\n",
    "#testset.obs['_indices'] = np.arange(testset.n_obs)\n",
    "scvi.model.MULTIVI.setup_anndata(testset, batch_key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File ..\u001b[35m/../results/trained_models/multiVI/mouse_gastrulation/l20_e2_d2_rs0_featselect0/\u001b[0m\u001b[95mmodel.pt\u001b[0m already   \n",
      "         downloaded                                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "data_name = \"mouse_gastrulation\"\n",
    "model_name = \"l20_e2_d2_rs0_featselect0\"\n",
    "model = scvi.model.MULTIVI.load(\n",
    "    save_dir+'multiVI/'+data_name+'/'+model_name,\n",
    "    adata=trainset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = None\n",
    "mudata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gex = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_test_counts_gex.npy')\n",
    "test_atac = np.load('../../results/analysis/performance_evaluation/reconstruction/mouse_gast_test_counts_atac.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expression_error(target, mod, scaling_factor, switch, batch_size=5000, error_type='rmse', feature_indices=None):\n",
    "    '''computes expression error for target (given as anndata object)'''\n",
    "    n_samples = target.shape[0]\n",
    "\n",
    "    errors = torch.zeros((n_samples))\n",
    "\n",
    "    for i in range(int(n_samples/batch_size)+1):\n",
    "        print('   ',round(i/(int(n_samples/batch_size))*100),'%')\n",
    "        start = i*batch_size\n",
    "        end = min((i+1)*batch_size,n_samples)\n",
    "        indices = np.arange(start,end,1)\n",
    "        #target.n_vars = switch # because of multivi\n",
    "        y_expression = mod.get_normalized_expression(target, indices=indices)\n",
    "        if type(y_expression) is not torch.Tensor:\n",
    "            if type(y_expression) == pd.core.frame.DataFrame:\n",
    "                y_expression = torch.from_numpy(y_expression.values)\n",
    "        y_expression *= scaling_factor[indices]\n",
    "        if feature_indices is not None:\n",
    "            y_expression = y_expression[:,feature_indices]\n",
    "            x_expression = torch.Tensor(target.X[indices,:switch].todense())[:,feature_indices]\n",
    "        else:\n",
    "            x_expression = torch.Tensor(target.X[indices,:switch].todense())\n",
    "        #print(y_expression[:10,:10])\n",
    "        #print(torch.Tensor(target.X[indices,:switch].todense())[:10,:10])\n",
    "        errors[indices] = compute_error_per_sample(x_expression, y_expression, reduction_type='ms')\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 %\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100 %\n"
     ]
    }
   ],
   "source": [
    "mvi_rna_errors = compute_expression_error(testset, model, library[:,0].unsqueeze(1), modality_switch_full, batch_size=5000, feature_indices=rna_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5686])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvi_rna_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.4637396335601807  +/-  0.021737542003393173\n"
     ]
    }
   ],
   "source": [
    "out_errors = torch.sqrt(mvi_rna_errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omicsdgd.functions._analysis import classify_binary_output, binary_output_scores\n",
    "\n",
    "def balanced_accuracy_with_sem(target, mod, scaling_factor, switch, threshold, batch_size=1000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, mod, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    #ba_mean = balanced_accuracy.clone().mean().item()\n",
    "    _, _, ba_mean, _, _ = binary_output_scores(target, mod, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    ba_error = balanced_accuracy.std() / math.sqrt(balanced_accuracy.shape[0])\n",
    "\n",
    "    return ba_mean, ba_error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "classifying binary output\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "balanced accuracy:  0.5196595191955566  +/-  4.284674650989473e-05\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data # original mean calc\n",
    "\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold, feature_indices=atac_indices)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.499816358089447  +/-  4.2846764699788764e-05\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\"\"\"\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold, feature_indices=atac_indices)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now the original model (on feature subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import mudata as md\n",
    "import scipy\n",
    "data_name = 'mouse_gastrulation'\n",
    "mudata = md.read(\"../../../data/mouse_gastrulation.h5mu\", backed=False)\n",
    "modality_switch = mudata[\"rna\"].X.shape[1]\n",
    "adata = ad.AnnData(scipy.sparse.hstack((mudata[\"rna\"].X, mudata[\"atac\"].X)))\n",
    "adata.obs = mudata.obs\n",
    "mudata = None\n",
    "adata.var[\"feature_type\"] = \"ATAC\"\n",
    "adata.var[\"feature_type\"][:modality_switch] = \"GEX\"\n",
    "train_indices = list(np.where(adata.obs[\"train_val_test\"] == \"train\")[0])\n",
    "test_indices = list(np.where(adata.obs[\"train_val_test\"] == \"test\")[0])\n",
    "adata.var_names_make_unique()\n",
    "adata.obs[\"modality\"] = \"paired\"\n",
    "trainset = adata[train_indices]\n",
    "testset = adata[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <08E12B12-6183-307E-BDA0-374FA8EBA2C9> /Users/dbm829/Library/Python/3.9/lib/python/site-packages/torchvision/image.so\n",
      "  Expected in:     <57D24B07-8B24-3888-A2B5-2B4C95434BA4> /Users/dbm829/Library/Python/3.9/lib/python/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/model/_multivi.py:1092: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"_indices\"] = np.arange(adata.n_obs)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/model/_multivi.py:1092: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"_indices\"] = np.arange(adata.n_obs)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n"
     ]
    }
   ],
   "source": [
    "import scvi\n",
    "scvi.model.MULTIVI.setup_anndata(trainset, batch_key='stage')\n",
    "scvi.model.MULTIVI.setup_anndata(testset, batch_key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File ..\u001b[35m/../results/trained_models/multiVI/mouse_gastrulation/l20_e2_d2/\u001b[0m\u001b[95mmodel.pt\u001b[0m already downloaded        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/scvi/data/fields/_layer_field.py:101: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  _verify_and_correct_data_format(adata, self.attr_name, self.attr_key)\n",
      "/Users/dbm829/Library/Python/3.9/lib/python/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'l20_e2_d2'\n",
    "model = scvi.model.MULTIVI.load(\n",
    "        save_dir+'multiVI/'+data_name+'/'+model_name,\n",
    "        adata=trainset\n",
    "    )\n",
    "trainset = None\n",
    "adata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 %\n",
      "    100 %\n",
      "RMSE:  2.342944383621216  +/-  0.02120981365442276\n"
     ]
    }
   ],
   "source": [
    "mvi_rna_errors = compute_expression_error(testset, model, torch.tensor(test_gex).sum(1).unsqueeze(1), modality_switch, batch_size=5000)\n",
    "out_errors = torch.sqrt(mvi_rna_errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "classifying binary output\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "balanced accuracy:  0.7121416330337524  +/-  0.00034910012618638575\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data # with original mean calc\n",
    "\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6968663930892944  +/-  0.00034910012618638575\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\"\"\"\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
