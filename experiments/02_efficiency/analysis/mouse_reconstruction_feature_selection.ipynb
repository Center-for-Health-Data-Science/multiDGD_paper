{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import math\n",
    "\n",
    "os.chdir('/Users/dbm829/Documents/work/Projects/GitHub/omicsDGD/')\n",
    "save_dir = 'results/trained_models/'\n",
    "data_name = 'mouse_gastrulation'\n",
    "random_seed = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_error_per_sample(target, output, reduction_type='ms'):\n",
    "    '''compute sample-wise error\n",
    "    It can be of type `ms` (mean squared) or `ma` (mean absolute)\n",
    "    '''\n",
    "    error = target - output\n",
    "    if reduction_type == 'ms':\n",
    "        return torch.mean(error**2, dim=-1)\n",
    "    elif reduction_type == 'ma':\n",
    "        return torch.mean(torch.abs(error), dim=-1)\n",
    "    else:\n",
    "        raise ValueError('invalid reduction type given. Can only be `ms` or `ma`.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_output_scores(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tp = tp.sum()\n",
    "    fp = fp.sum()\n",
    "    tn = tn.sum()\n",
    "    fn = fn.sum()\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    positive_likelihood_ratio = tpr/fpr\n",
    "    negative_likelihood_ratio = fnr/tnr\n",
    "\n",
    "    return tpr.item(), tnr.item(), balanced_accuracy.item(), positive_likelihood_ratio.item(), negative_likelihood_ratio.item()\n",
    "\n",
    "def balanced_accuracy_with_sem(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    ba_mean = balanced_accuracy.clone().mean()\n",
    "    ba_error = balanced_accuracy.std() / math.sqrt(balanced_accuracy.shape[0])\n",
    "\n",
    "    return ba_mean.item(), ba_error.item()\n",
    "\n",
    "def classify_binary_output(target, output, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''calculating true positives, false positives, true negatives and false negatives'''\n",
    "    print('classifying binary output')\n",
    "    \n",
    "    n_samples = target.shape[0]\n",
    "    true_positives = torch.zeros((n_samples))\n",
    "    false_positives = torch.zeros((n_samples))\n",
    "    true_negatives = torch.zeros((n_samples))\n",
    "    false_negatives = torch.zeros((n_samples))\n",
    "    \n",
    "    for i in range(int(n_samples/batch_size)+1):\n",
    "        print(round(i/(int(n_samples/batch_size))*100),'%')\n",
    "        start = i*batch_size\n",
    "        end = min((i+1)*batch_size,n_samples)\n",
    "        indices = np.arange(start,end,1)\n",
    "        x_accessibility = binarize(torch.Tensor(target[indices,:])).int()\n",
    "        y_accessibility = output[indices,:]\n",
    "        if type(y_accessibility) is not torch.Tensor:\n",
    "            if type(y_accessibility) == pd.core.frame.DataFrame:\n",
    "                y_accessibility = torch.from_numpy(y_accessibility.values)\n",
    "                y_accessibility = y_accessibility.detach().cpu()\n",
    "        else:\n",
    "            y_accessibility = y_accessibility.detach().cpu()*scaling_factor[indices]\n",
    "        y_accessibility = binarize(y_accessibility, threshold).int()\n",
    "        if feature_indices is not None:\n",
    "            x_accessibility = x_accessibility[:,feature_indices]\n",
    "            y_accessibility = y_accessibility[:,feature_indices]\n",
    "        p = (x_accessibility == 1)\n",
    "        pp = (y_accessibility == 1)\n",
    "        true_positives[indices] = torch.logical_and(p,pp).sum(-1).float()\n",
    "        true_negatives[indices] = torch.logical_and(~p,~pp).sum(-1).float()\n",
    "        false_positives[indices] = (y_accessibility > x_accessibility).sum(-1).float()\n",
    "        false_negatives[indices] = (y_accessibility < x_accessibility).sum(-1).float()\n",
    "    \n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "def binarize(x, threshold=0.5):\n",
    "    x[x >= threshold] = 1\n",
    "    x[x < threshold] = 0\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recalculate losses for sample-wise with SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test and reconstructions from the saved files\n",
    "test_gex = np.load('results/analysis/performance_evaluation/reconstruction/mouse_test_counts_gex.npy')\n",
    "recon_gex = np.load('results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_test_recon_gex.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.714585781097412  +/-  0.012759659439325333\n"
     ]
    }
   ],
   "source": [
    "n_samples = test_gex.shape[0]\n",
    "errors = compute_error_per_sample(torch.tensor(test_gex), torch.tensor(recon_gex)*torch.tensor(test_gex).sum(axis=1).unsqueeze(1), reduction_type='ms')\n",
    "out_errors = torch.sqrt(errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test and reconstructions from the saved files\n",
    "test_atac = np.load('results/analysis/performance_evaluation/reconstruction/test_counts_atac.npy')\n",
    "recon_atac = np.load('results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_test_recon_atac.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6746575236320496  +/-  0.0006929467199370265\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.2\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6781863570213318  +/-  0.000710424268618226\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.25\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now make a file for the feature selection indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n"
     ]
    }
   ],
   "source": [
    "# get the data and the indices of the overlapping features\n",
    "# first the full set\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import mudata as md\n",
    "gex = ad.read_h5ad('data/mouse_gastrulation/raw/anndata.h5ad')\n",
    "atac = ad.read_h5ad('data/mouse_gastrulation/raw/PeakMatrix_anndata.h5ad')\n",
    "ids_shared = list(set(gex.obs['sample'].index.values).intersection(set(atac.obs['sample'].index.values)))\n",
    "ids_gex = np.where(gex.obs['sample'].index.isin(ids_shared))[0]\n",
    "ids_atac = np.where(atac.obs['sample'].index.isin(ids_shared))[0]\n",
    "gex = gex[ids_gex]\n",
    "atac = atac[ids_atac]\n",
    "threshold = 0.00\n",
    "mudata = md.MuData({'rna': gex, 'atac': atac})\n",
    "mudata.obs['stage'] = mudata['atac'].obs['stage']\n",
    "mudata.obs['celltype'] = mudata['rna'].obs['celltype']\n",
    "is_train_df = pd.read_csv('data/mouse_gastrulation/train_val_test_split.csv')\n",
    "trainset = mudata[list(is_train_df[is_train_df['is_train'] == 'train']['num_idx'].values)].copy()\n",
    "testset = mudata[list(is_train_df[is_train_df['is_train'] == 'iid_holdout']['num_idx'].values)].copy()\n",
    "mudata, gex, atac = None, None, None\n",
    "modality_switch_full = testset['rna'].X.shape[1]\n",
    "\n",
    "# now the subset\n",
    "data_subset = md.read('data/mouse_gastrulation/mudata.h5mu', backed=False)\n",
    "rna_indices = [i for i, x in enumerate(testset.var.index) if x in data_subset['rna'].var.index]\n",
    "atac_indices = [i-modality_switch_full for i, x in enumerate(testset.var.index) if x in data_subset['atac'].var.index]\n",
    "\n",
    "# save indices as csv file\n",
    "indices_df = pd.concat(\n",
    "    (pd.DataFrame({'idx': rna_indices,\n",
    "                           'modality': 'rna'}),\n",
    "    pd.DataFrame({'idx': atac_indices,\n",
    "                           'modality': 'atac'})), axis=0\n",
    ")\n",
    "#indices_df.to_csv('data/mouse_gastrulation/five_percent_indices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_gex = np.load('results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_scale5_featselect0_test_recon_gex.npy')\n",
    "recon_gex = recon_gex[:, rna_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.6939202547073364  +/-  0.01272590272128582\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "n_samples = test_gex.shape[0]\n",
    "errors = compute_error_per_sample(torch.tensor(test_gex), torch.tensor(recon_gex)*torch.tensor(test_gex).sum(axis=1).unsqueeze(1), reduction_type='ms')\n",
    "out_errors = torch.sqrt(errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_atac = np.load('results/analysis/performance_evaluation/reconstruction/mouse_gast_l20_h2-2_rs0_scale5_featselect0_test_recon_atac.npy')\n",
    "recon_atac = recon_atac[:, atac_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6792690753936768  +/-  0.0007066355901770294\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.2\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(test_atac, torch.tensor(recon_atac), torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = torch.cat(\n",
    "    (torch.tensor(np.asarray(testset['rna'].X.sum(-1))),\n",
    "    torch.tensor(np.asarray(testset['atac'].X.sum(-1)))),\n",
    "    dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the model on all data\n",
    "\n",
    "import scipy\n",
    "import scvi\n",
    "train_stages = trainset.obs['stage'].values\n",
    "test_stages = testset.obs['stage'].values\n",
    "# now VAE\n",
    "trainset = ad.AnnData(scipy.sparse.hstack((trainset['rna'].X,trainset['atac'].X))) # making test set anndata\n",
    "trainset.var_names_make_unique()\n",
    "trainset.obs['stage'] = train_stages\n",
    "trainset.obs['modality'] = 'paired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>MuData object with n_obs × n_vars = 5686 × 224536\n",
       "  obs:\t&#x27;stage&#x27;, &#x27;celltype&#x27;, &#x27;modality&#x27;, &#x27;_indices&#x27;\n",
       "  2 modalities\n",
       "    rna:\t5686 x 32285\n",
       "      obs:\t&#x27;barcode&#x27;, &#x27;sample&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;nCount_RNA&#x27;, &#x27;mitochondrial_percent_RNA&#x27;, &#x27;ribosomal_percent_RNA&#x27;, &#x27;stage&#x27;, &#x27;genotype&#x27;, &#x27;pass_rnaQC&#x27;, &#x27;doublet_score&#x27;, &#x27;doublet_call&#x27;, &#x27;celltype&#x27;, &#x27;celltype.score&#x27;, &#x27;closest.cell&#x27;\n",
       "      var:\t&#x27;gene&#x27;\n",
       "    atac:\t5686 x 192251\n",
       "      obs:\t&#x27;BlacklistRatio&#x27;, &#x27;nDiFrags&#x27;, &#x27;nFrags&#x27;, &#x27;nMonoFrags&#x27;, &#x27;nMultiFrags&#x27;, &#x27;NucleosomeRatio&#x27;, &#x27;PassQC&#x27;, &#x27;PromoterRatio&#x27;, &#x27;ReadsInBlacklist&#x27;, &#x27;ReadsInPromoter&#x27;, &#x27;ReadsInTSS&#x27;, &#x27;Sample&#x27;, &#x27;TSSEnrichment&#x27;, &#x27;barcode&#x27;, &#x27;sample&#x27;, &#x27;nFeature_RNA&#x27;, &#x27;nCount_RNA&#x27;, &#x27;mitochondrial_percent_RNA&#x27;, &#x27;ribosomal_percent_RNA&#x27;, &#x27;stage&#x27;, &#x27;genotype&#x27;, &#x27;pass_rnaQC&#x27;, &#x27;doublet_score&#x27;, &#x27;doublet_call&#x27;, &#x27;celltype.mapped&#x27;, &#x27;celltype.score&#x27;, &#x27;closest.cell&#x27;, &#x27;TSSEnrichment_atac&#x27;, &#x27;ReadsInTSS_atac&#x27;, &#x27;PromoterRatio_atac&#x27;, &#x27;NucleosomeRatio_atac&#x27;, &#x27;nFrags_atac&#x27;, &#x27;BlacklistRatio_atac&#x27;, &#x27;ReadsInPeaks&#x27;, &#x27;FRIP&#x27;, &#x27;cell&#x27;\n",
       "      var:\t&#x27;idx&#x27;, &#x27;chr&#x27;, &#x27;start&#x27;, &#x27;end&#x27;\n",
       "      uns:\t&#x27;celltype_colors&#x27;, &#x27;stage_colors&#x27;</pre>"
      ],
      "text/plain": [
       "MuData object with n_obs × n_vars = 5686 × 224536\n",
       "  obs:\t'stage', 'celltype', 'modality', '_indices'\n",
       "  2 modalities\n",
       "    rna:\t5686 x 32285\n",
       "      obs:\t'barcode', 'sample', 'nFeature_RNA', 'nCount_RNA', 'mitochondrial_percent_RNA', 'ribosomal_percent_RNA', 'stage', 'genotype', 'pass_rnaQC', 'doublet_score', 'doublet_call', 'celltype', 'celltype.score', 'closest.cell'\n",
       "      var:\t'gene'\n",
       "    atac:\t5686 x 192251\n",
       "      obs:\t'BlacklistRatio', 'nDiFrags', 'nFrags', 'nMonoFrags', 'nMultiFrags', 'NucleosomeRatio', 'PassQC', 'PromoterRatio', 'ReadsInBlacklist', 'ReadsInPromoter', 'ReadsInTSS', 'Sample', 'TSSEnrichment', 'barcode', 'sample', 'nFeature_RNA', 'nCount_RNA', 'mitochondrial_percent_RNA', 'ribosomal_percent_RNA', 'stage', 'genotype', 'pass_rnaQC', 'doublet_score', 'doublet_call', 'celltype.mapped', 'celltype.score', 'closest.cell', 'TSSEnrichment_atac', 'ReadsInTSS_atac', 'PromoterRatio_atac', 'NucleosomeRatio_atac', 'nFrags_atac', 'BlacklistRatio_atac', 'ReadsInPeaks', 'FRIP', 'cell'\n",
       "      var:\t'idx', 'chr', 'start', 'end'\n",
       "      uns:\t'celltype_colors', 'stage_colors'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/scvi/data/_utils.py:114: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scvi.model.MULTIVI.setup_anndata(trainset, batch_key='stage')\n",
    "testset = ad.AnnData(scipy.sparse.hstack((testset['rna'].X,testset['atac'].X)))\n",
    "testset.var_names_make_unique()\n",
    "testset.obs['stage'] = test_stages\n",
    "testset.obs['modality'] = 'paired'\n",
    "#testset.obs['_indices'] = np.arange(testset.n_obs)\n",
    "scvi.model.MULTIVI.setup_anndata(testset, batch_key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File results/trained_models/multiVI/mouse_gastrulation/l20_e2_d2_rs0_featselect0/model.pt already         \n",
      "         downloaded                                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/scvi/data/_utils.py:114: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "data_name = \"mouse_gastrulation\"\n",
    "model_name = \"l20_e2_d2_rs0_featselect0\"\n",
    "model = scvi.model.MULTIVI.load(\n",
    "    save_dir+'multiVI/'+data_name+'/'+model_name,\n",
    "    adata=trainset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expression_error(target, mod, scaling_factor, switch, batch_size=5000, error_type='rmse', feature_indices=None):\n",
    "    '''computes expression error for target (given as anndata object)'''\n",
    "    n_samples = target.shape[0]\n",
    "\n",
    "    errors = torch.zeros((n_samples))\n",
    "\n",
    "    for i in range(int(n_samples/batch_size)+1):\n",
    "        print('   ',round(i/(int(n_samples/batch_size))*100),'%')\n",
    "        start = i*batch_size\n",
    "        end = min((i+1)*batch_size,n_samples)\n",
    "        indices = np.arange(start,end,1)\n",
    "        #target.n_vars = switch # because of multivi\n",
    "        y_expression = mod.get_normalized_expression(target, indices=indices)\n",
    "        if type(y_expression) is not torch.Tensor:\n",
    "            if type(y_expression) == pd.core.frame.DataFrame:\n",
    "                y_expression = torch.from_numpy(y_expression.values)\n",
    "        y_expression *= scaling_factor[indices]\n",
    "        if feature_indices is not None:\n",
    "            y_expression = y_expression[:,feature_indices]\n",
    "            x_expression = torch.Tensor(target.X[indices,:switch].todense())[:,feature_indices]\n",
    "        else:\n",
    "            x_expression = torch.Tensor(target.X[indices,:switch].todense())\n",
    "        #print(y_expression[:10,:10])\n",
    "        #print(torch.Tensor(target.X[indices,:switch].todense())[:10,:10])\n",
    "        errors[indices] = compute_error_per_sample(x_expression, y_expression, reduction_type='ms')\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 %\n",
      "    100 %\n"
     ]
    }
   ],
   "source": [
    "mvi_rna_errors = compute_expression_error(testset, model, library[:,0].unsqueeze(1), modality_switch_full, batch_size=5000, feature_indices=rna_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5686])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvi_rna_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.4637396335601807  +/-  0.021737542003393173\n"
     ]
    }
   ],
   "source": [
    "out_errors = torch.sqrt(mvi_rna_errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omicsdgd.functions._analysis import classify_binary_output\n",
    "\n",
    "def balanced_accuracy_with_sem(target, mod, scaling_factor, switch, threshold, batch_size=5000, feature_indices=None):\n",
    "    '''returns FPR, FNR, balanced accuracy, LR+ and LR-'''\n",
    "    tp, fp, tn, fn = classify_binary_output(target, mod, scaling_factor, switch, threshold, batch_size, feature_indices)\n",
    "    tpr = tp / (tp + fn) # sensitivity\n",
    "    tnr = tn / (tn + fp) # specificity\n",
    "    fpr = 1 - tnr\n",
    "    fnr = 1 - tpr\n",
    "    balanced_accuracy = (tpr + tnr) / 2\n",
    "    ba_mean = balanced_accuracy.clone().mean()\n",
    "    ba_error = balanced_accuracy.std() / math.sqrt(balanced_accuracy.shape[0])\n",
    "\n",
    "    return ba_mean.item(), ba_error.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.499816358089447  +/-  4.2846764699788764e-05\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold, feature_indices=atac_indices)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now the original model (on feature subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n",
      "/usr/local/lib/python3.10/site-packages/mudata/_core/mudata.py:578: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data_mod.loc[:, colname] = col\n"
     ]
    }
   ],
   "source": [
    "data_name = 'mouse_gastrulation'\n",
    "from omicsdgd.functions._data_manipulation import load_testdata_as_anndata\n",
    "trainset, testset, modality_switch, library = load_testdata_as_anndata(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/scvi/data/_utils.py:114: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/scvi/data/_utils.py:114: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainset.var_names_make_unique()\n",
    "trainset.obs['modality'] = 'paired'\n",
    "#trainset.obs['_indices'] = np.arange(trainset.n_obs)\n",
    "scvi.model.MULTIVI.setup_anndata(trainset, batch_key='stage')\n",
    "testset.var_names_make_unique()\n",
    "testset.obs['modality'] = 'paired'\n",
    "#testset.obs['_indices'] = np.arange(testset.n_obs)\n",
    "scvi.model.MULTIVI.setup_anndata(testset, batch_key='stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File results/trained_models/multiVI/mouse_gastrulation/l20_e2_d2/model.pt already downloaded              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/scvi/model/base/_utils.py:142: UserWarning: var_names for adata passed in does not match var_names of adata used to train the model. For valid results, the vars need to be the same and in the same order as the adata used to train the model.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/scvi/data/_utils.py:114: UserWarning: Training will be faster when sparse matrix is formatted as CSR. It is safe to cast before model initialization.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'l20_e2_d2'\n",
    "model = scvi.model.MULTIVI.load(\n",
    "        save_dir+'multiVI/'+data_name+'/'+model_name,\n",
    "        adata=trainset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 %\n",
      "    100 %\n",
      "RMSE:  2.342944383621216  +/-  0.02120981365442276\n"
     ]
    }
   ],
   "source": [
    "mvi_rna_errors = compute_expression_error(testset, model, torch.tensor(test_gex).sum(1).unsqueeze(1), modality_switch, batch_size=5000)\n",
    "out_errors = torch.sqrt(mvi_rna_errors)\n",
    "out_error_mean = out_errors.clone().mean()\n",
    "out_error_se = out_errors.clone().std() / math.sqrt(test_gex.shape[0])\n",
    "print('RMSE: ', out_error_mean.item(), ' +/- ', out_error_se.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifying binary output\n",
      "0 %\n",
      "100 %\n",
      "balanced accuracy:  0.6968663930892944  +/-  0.00034910012618638575\n"
     ]
    }
   ],
   "source": [
    "# compute loss for ATAC data\n",
    "\n",
    "threshold = 0.5\n",
    "balanced_accuracy_mean, balanced_accuracy_sem = balanced_accuracy_with_sem(testset, model, torch.tensor(test_atac).sum(1).unsqueeze(1), test_gex.shape[1], threshold)\n",
    "print('balanced accuracy: ', balanced_accuracy_mean, ' +/- ', balanced_accuracy_sem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
